{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6c27a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy \n",
    "import os\n",
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97de80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_battery = pd.read_csv('Battery_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85eec238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold \n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "import statistics as stcs\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV       \n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.utils import resample\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0441e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding (alphebetical order)\n",
    "ohe = OneHotEncoder()\n",
    "ACE = df_battery.loc[:,['anode','cathode','electrolyte']]\n",
    "ACE = ohe.fit_transform(ACE)\n",
    "ACE = pd.DataFrame(ACE.toarray())\n",
    "\n",
    "ACE_col_name = ['A1','C1','C2','C3','E1','E2','E3']\n",
    "for i in range(len(ACE.columns)):\n",
    "    ACE = ACE.rename({ACE.columns[i]: ACE_col_name[i]}, axis=1) \n",
    "    \n",
    "df_battery = pd.concat([ACE, df_battery],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534f7547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_battery\n",
    "\n",
    "np.random.seed(66)\n",
    "def data_split (data, test_ratio):\n",
    "    \n",
    "    total_row = df_battery.shape[0]\n",
    "    test_row = round(total_row *test_ratio)\n",
    "    train_row = total_row - test_row\n",
    "    \n",
    "    indices =np.random.permutation(total_row)\n",
    "    train_indx, test_idx =indices[:train_row], indices[train_row:]\n",
    "    train,test = df_battery.iloc[train_indx,:], df_battery.iloc[test_idx,:]\n",
    "\n",
    "    X_test = test[['A1','C1','C2','C3','E1','E2','E3','Cycle','temperature','discharge_crate']]\n",
    "#    y_test = test[['Charge_Capacity (Ah)']]\n",
    "#    y_test = test[['Discharge_Capacity (Ah)']]\n",
    "#    y_test = test[['Charge_Energy (Wh)']]\n",
    "    y_test = test[['Discharge_Energy (Wh)']]\n",
    "#    y_test = test[['Coulombic_Efficiency (%)']]\n",
    "#    y_test = test[['Energy_Efficiency (%)']]\n",
    "    X_train = train[['A1','C1','C2','C3','E1','E2','E3','Cycle','temperature','discharge_crate']]\n",
    "#    y_train = train[['Charge_Capacity (Ah)']]\n",
    "#    y_train = train[['Discharge_Capacity (Ah)']]\n",
    "#    y_train = train[['Charge_Energy (Wh)']]\n",
    "    y_train = train[['Discharge_Energy (Wh)']]\n",
    "#    y_train = train[['Coulombic_Efficiency (%)']]\n",
    "#    y_train = train[['Energy_Efficiency (%)']]\n",
    "    return train,test,X_train,y_train,X_test,y_test\n",
    "    \n",
    "train,test,X_train,y_train,X_test,y_test = data_split(data,0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806261b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1523d86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a758e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,random_state =66,shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fb88a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'splitter': 'best', 'min_weight_fraction_leaf': 0.2, 'min_samples_leaf': 10, 'max_leaf_nodes': 60, 'max_features': None, 'max_depth': 11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "40 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "40 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 304, in fit\n",
      "    raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
      "ValueError: min_weight_fraction_leaf must in [0, 0.5]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.29296009        nan 0.5572727         nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "rand_para = {\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n",
    "\n",
    "svm_model = DecisionTreeRegressor()\n",
    "n_iteration = 200\n",
    "Scoring = ['explained_variance','neg_mean_squared_error',\"r2\"]\n",
    "random_search = RandomizedSearchCV(\n",
    "    svm_model,\n",
    "    param_distributions=rand_para,\n",
    "    cv =5)\n",
    "#     scoring=Scoring,\n",
    "#     error_score=0,\n",
    "#     random_state=66,\n",
    "#     return_train_score=True,\n",
    "#     n_jobs=-1,\n",
    "#     n_iter=n_iteration,\n",
    "#     verbose=10,\n",
    "#     refit=False)\n",
    "\n",
    "\n",
    "\n",
    "random_search.fit(X_train,y_train)\n",
    "\n",
    "#y_predict=random_search.predict(X_test)\n",
    "#math.sqrt(stcs.mean((y_predict-y_test)**2))\n",
    "\n",
    "print('Best hyperparameters: ', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e1d62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'splitter': 'random', 'min_weight_fraction_leaf': 0.3, 'min_samples_leaf': 10, 'max_leaf_nodes': 50, 'max_features': None, 'max_depth': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 1315, in fit\n",
      "    super().fit(\n",
      "  File \"/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 304, in fit\n",
      "    raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
      "ValueError: min_weight_fraction_leaf must in [0, 0.5]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/kli625/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [-0.00620928  0.48724177  0.56577973  0.24469422         nan  0.56577973\n",
      "  0.28608634  0.56577973         nan  0.45798056]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Tuning hyperparameters\n",
    "rand_para = {\"splitter\":[\"best\",\"random\"],\n",
    "            \"max_depth\" : [1,3,5,7,9,11,12],\n",
    "           \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n",
    "           \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "           \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n",
    "           \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n",
    "\n",
    "svm_model = DecisionTreeRegressor()\n",
    "n_iteration = 200\n",
    "Scoring = ['explained_variance','neg_mean_squared_error',\"r2\"]\n",
    "random_search = RandomizedSearchCV(\n",
    "    svm_model,\n",
    "    param_distributions=rand_para,\n",
    "    cv =5)\n",
    "#     scoring=Scoring,\n",
    "#     error_score=0,\n",
    "#     random_state=66,\n",
    "#     return_train_score=True,\n",
    "#     n_jobs=-1,\n",
    "#     n_iter=n_iteration,\n",
    "#     verbose=10,\n",
    "#     refit=False)\n",
    "\n",
    "\n",
    "\n",
    "random_search.fit(X_train,y_train)\n",
    "\n",
    "#y_predict=random_search.predict(X_test)\n",
    "#math.sqrt(stcs.mean((y_predict-y_test)**2))\n",
    "\n",
    "print('Best hyperparameters: ', random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f363e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-error\n",
    "np.random.seed(66)\n",
    "\n",
    "DT_model_train = DecisionTreeRegressor(random_state = 66)\n",
    "\n",
    "train_results =[]\n",
    "train_results_name =['Experimental','Predicted ','RMSE']\n",
    "\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    #print(\"Train:\", train_index, \"Validation:\", test_index)\n",
    "    X_training, X_validate = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_training, y_validate = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "    \n",
    "    np.random.seed(66)\n",
    "    DT_model_train .fit(X_training,y_training)\n",
    "    y_train_predicted = DT_model_train.predict(X_validate)\n",
    "    number_validate =X_validate.shape[0]\n",
    "    #print(y_train_predicted.shape)\n",
    "    mse = mean_squared_error(y_train_predicted, y_validate)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    #squared_deviations=(y_train_predicted.reshape(-1,1)-y_validate)**2\n",
    "    #RMSE=math.sqrt(squared_deviations.sum()/number_validate)\n",
    "    #RMSE = math.sqrt(stcs.mean((y_train_predicted-y_validate)**2))\n",
    "    train_results.append([y_validate,y_train_predicted,RMSE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e9ae802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.34078169094921"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_results =pd.DataFrame (train_results,columns=train_results_name)\n",
    "np.average(Train_results['RMSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb5e739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test-set Validation\n",
    "DecisionTree_model =DecisionTreeRegressor(random_state = 66)\n",
    "\n",
    "np.random.seed(66)\n",
    "DecisionTree_model.fit(X_train,y_train)\n",
    "y_predict=DecisionTree_model.predict(X_test)\n",
    "#print(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd054111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5870270144390646"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_test = X_test.shape[0]\n",
    "mse = mean_squared_error(y_predict, y_test)\n",
    "RMSE = np.sqrt(mse)\n",
    "RMSE\n",
    "# squared_deviations=(y_predict.reshape(-1,1)-y_test)**2\n",
    "# math.sqrt(squared_deviations.sum()/number_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd9a386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8550cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
